{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Built-in modules\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# 3rd party modules\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Local modules\n",
    "#import utils as ut\n",
    "#import numpy as np\n",
    "\n",
    "# Useful directories\n",
    "RESULT_DIR = os.path.join('results')\n",
    "TRAIN_MUSEUM_DIR = os.path.join('dataset', 'museum_set_random')\n",
    "TRAIN_QUERY_DIR = os.path.join('dataset', 'query_devel_random')\n",
    "\n",
    "\n",
    "# Pickle filename with the training data\n",
    "PICKLE_MUSEUM_DATASET = 'train_museum.pkl'\n",
    "PICKLE_QUERY_DATASET = 'train_query.pkl'\n",
    "\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "img1 = cv.imread('../dataset/query_devel_W4/ima_000007.jpg',0)          # queryImage\n",
    "#img2 = cv.imread('../dataset/BBDD_W4/ima_000035.jpg',0) # trainImage\n",
    "#img2 = cv.imread('../dataset/BBDD_W4/ima_000048.jpg',0) # trainImage\n",
    "img2 = cv.imread('../dataset/BBDD_W4/ima_000089.jpg',0) # trainImage\n",
    "\n",
    "# Initiate ORB detector\n",
    "orb = cv.ORB_create()\n",
    "\n",
    "# find the keypoints and descriptors with ORB\n",
    "kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "\n",
    "'''\n",
    "# create BFMatcher object\n",
    "bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "# Match descriptors.\n",
    "matches = bf.match(des1,des2)\n",
    "# Sort them in the order of their distance.\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "# Draw first 10 matches.\n",
    "img3 = cv.drawMatches(img1,kp1,img2,kp2,matches[:10], outImg=None, flags=2)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(img3),plt.show()\n",
    "'''\n",
    "def match_kpt(des1, des2, n_matches, thresh):\n",
    "    \n",
    "    # create BFMatcher object\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "    # Match descriptors.\n",
    "    matches = bf.match(des1,des2)\n",
    "    # Sort them in the order of their distance.\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "    dist = []\n",
    "    for m in matches[:n_matches]:\n",
    "        dist.append(m.distance)\n",
    "\n",
    "    sqrt_sum = np.sum(np.array(dist)**2) / n_matches\n",
    "    \n",
    "    return sqrt_sum <= thresh\n",
    "    \n",
    "result = match_kpt(des1, des2, 10, 500)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = []\n",
    "for m in matches[:10]:\n",
    "    dist.append(m.distance)\n",
    "\n",
    "sqrt_sum = np.sum(np.array(dist)**2)/10\n",
    "\n",
    "print(sqrt_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ut\n",
    "\n",
    "gt = [[0, [-1]], [1, [-1]], [2, [115]], [3, [-1]], [4, [-1]], [5, [99]], [6, [-1]], [7, [89]], [8, [19]], [9, [85]], [10, [90]], [11, [121, 117]], [12, [-1]], [13, [-1]], [14, [130]], [15, [6, 84]], [16, [35, 48, 52]], [17, [118]], [18, [-1]], [19, [-1]], [20, [-1]], [21, [-1]], [22, [60]], [23, [119, 128]], [24, [-1]], [25, [47]], [26, [-1]], [27, [41]], [28, [-1]], [29, [126, 123]]]\n",
    "\n",
    "dbn = '../dataset/BBDD_W4/'\n",
    "qn = '../dataset/query_devel_W4/'\n",
    "\n",
    "dict_db = ut.get_files_from_dir(dbn)\n",
    "dict_q = ut.get_files_from_dir(qn)\n",
    "\n",
    "dict_db = np.sort(dict_db)\n",
    "dict_q = np.sort(dict_q)\n",
    "\n",
    "#print(dict_q)\n",
    "for v in gt:\n",
    "    if v[1] != [-1]:\n",
    "        \n",
    "        for v_db in v[1]:\n",
    "\n",
    "            #print(dict_q[v[0]])\n",
    "            q_name = os.path.join(qn, dict_q[v[0]])\n",
    "            db_name = os.path.join(dbn,dict_db[v_db])\n",
    "            \n",
    "            print(q_name, db_name)\n",
    "            \n",
    "            q = cv.imread(q_name)\n",
    "            db = cv.imread(db_name)\n",
    "            \n",
    "            #plt.imshow(q)\n",
    "            #plt.imshow(db)\n",
    "            #plt.show()\n",
    "            '''\n",
    "            fig, axs = plt.subplots(nrows=1, ncols=2, sharex=True)\n",
    "            ax = axs[0]\n",
    "            ax.imshow(q)\n",
    "            ax = axs[1]\n",
    "            ax.imshow(db)\n",
    "            '''\n",
    "            orb = cv.ORB_create()\n",
    "\n",
    "            # find the keypoints and descriptors with ORB\n",
    "            kp1, des1 = orb.detectAndCompute(q,None)\n",
    "            kp2, des2 = orb.detectAndCompute(db,None)\n",
    "\n",
    "\n",
    "            # create BFMatcher object\n",
    "            bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "            # Match descriptors.\n",
    "            matches = bf.match(des1,des2)\n",
    "            # Sort them in the order of their distance.\n",
    "            matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "            n_matches = 10\n",
    "\n",
    "            dist = []\n",
    "            for m in matches[:n_matches]:\n",
    "                dist.append(m.distance)\n",
    "\n",
    "            sqrt_sum = np.sum(np.array(dist)**2) / n_matches\n",
    "\n",
    "            print(sqrt_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
