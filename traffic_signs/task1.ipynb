{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# item 1 - Analyze the dataset\n",
    "Parse the groundtruth information into a dictionary and a pandas table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path_txt = os.path.join('dataset', 'train', 'gt')\n",
    "path_mask = os.path.join('dataset', 'train', 'mask')\n",
    "\n",
    "dirs_txt = os.listdir(path_txt)\n",
    "dirs_mask = os.listdir(path_mask)\n",
    "\n",
    "data = dict()\n",
    "\n",
    "for gt in dirs_txt:\n",
    "    with open(os.path.join(path_txt, gt)) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        im_name = gt.replace('gt', 'mask').replace('txt', 'png')\n",
    "        im_open = (imageio.imread(os.path.join(path_mask, im_name)))\n",
    "\n",
    "        lista = list()\n",
    "        \n",
    "        # Extract grountruth information\n",
    "        for l in lines:\n",
    "            tly, tlx, bry, brx, tipo = l.split(' ')  \n",
    "            tly, tlx, bry, brx = map(float, [tly, tlx, bry, brx])\n",
    "            d = dict()\n",
    "            d['type'] = tipo.strip()\n",
    "            \n",
    "            w = brx - tlx\n",
    "            h = bry - tly\n",
    "            \n",
    "            d['width'] = w\n",
    "            d['height'] = h\n",
    "            d['bbox_area'] = w*h\n",
    "            d['form_factor'] = w/h\n",
    "            \n",
    "            d['tly'] = round(tly)\n",
    "            d['tlx'] = round(tlx)\n",
    "            d['bry'] = round(bry)\n",
    "            d['brx'] = round(brx)\n",
    "            \n",
    "            sub_mask = im_open[d['tly']:d['bry'], d['tlx']:d['brx']]\n",
    "            mask_area = np.count_nonzero(sub_mask)\n",
    "            d['mask_area'] = mask_area\n",
    "            d['filling_ratio'] = mask_area / d['bbox_area']\n",
    "            \n",
    "            lista.append(d)\n",
    "            \n",
    "        data[gt] = lista\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show information in pandas format\n",
    "columns = ['type','width','height','form_factor','bbox_area','mask_area','filling_ratio']\n",
    "df = pd.DataFrame.from_dict({(i,n): data[i][n]\n",
    "                        for i in data.keys()\n",
    "                        for n,v in enumerate(data[i])}, columns=columns, orient='index').sort_values(['type'])\n",
    "#print(df)\n",
    "#df['form_factor'].plot(figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Statistical calculations\n",
    "type_counts = df.groupby('type').aggregate(np.std).round(2)\n",
    "type_counts\n",
    "\n",
    "#type_counts = df.groupby('type').aggregate(np.median)\n",
    "#type_counts = df.groupby('type').aggregate(np.average)\n",
    "#type_counts = df.groupby('type').aggregate(np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by \"type\" (letter) and get statistics:\n",
    "\n",
    "# Function = get_stats (only shape, aspect ratio, etc, NOT COLOUR)\n",
    "\n",
    "# Queremos estadisticas de tamaño y forma en función de cada letra        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item 2 - Split training dataset\n",
    "\n",
    "Extract the 30% of the training images of each class to set up a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of signals per class\n",
    "n_signals = df['type'].value_counts(sort=False).reindex(['A','B','C','D','E','F'])\n",
    "print(n_signals)\n",
    "\n",
    "# Plot\n",
    "df['type'].value_counts(sort=False).reindex(['A','B','C','D','E','F']).plot(figsize=(10, 7),kind='bar',sort_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only one class\n",
    "df_filtered = df[df['type'] == \"B\"]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_train = df_filtered.sample(frac=0.7)\n",
    "df_sorted_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train selection\n",
    "tuple(zip(df_sorted_train.index.get_level_values(0).tolist(),df_sorted_train.index.get_level_values(1).tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete train selection to get validation selection\n",
    "df_sorted_test = pd.concat([df_filtered,df_sorted_train]).drop_duplicates(keep=False)\n",
    "tuple(zip(df_sorted_test.index.get_level_values(0).tolist(),df_sorted_test.index.get_level_values(1).tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to do all the process in one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_class(signal_class, train_percentage):\n",
    "    \n",
    "    # Choose one signal class\n",
    "    df_filtered = df[df['type'] == signal_class]\n",
    "    \n",
    "    # Sample randomly the percentage choosen\n",
    "    df_sorted_train = df_filtered.sample(frac=train_percentage)\n",
    "    \n",
    "    # Save train selection\n",
    "    train_images = tuple(zip(df_sorted_train.index.get_level_values(0).tolist(),df_sorted_train.index.get_level_values(1).tolist()))\n",
    "    \n",
    "    # Delete train selection to get validation selection\n",
    "    df_sorted_test = pd.concat([df_filtered,df_sorted_train]).drop_duplicates(keep=False)\n",
    "    val_images = tuple(zip(df_sorted_test.index.get_level_values(0).tolist(),df_sorted_test.index.get_level_values(1).tolist()))\n",
    "    \n",
    "    return train_images, val_images\n",
    "\n",
    "def split_dataset(data,percentage, classes):\n",
    "    \n",
    "    train_images = []\n",
    "    val_images = []\n",
    "    \n",
    "    for signal_class in classes:\n",
    "        temp_train_images, temp_val_images = split_class(signal_class, percentage)\n",
    "        train_images += temp_train_images\n",
    "        val_images += temp_val_images\n",
    "    return train_images, val_images\n",
    "\n",
    "\n",
    "classes = ['A','B','C','D','E','F']\n",
    "train_images, val_images = split_dataset(data, 0.7, classes)\n",
    "#print(train_images)\n",
    "#print(val_images)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item 3 - Separation by colour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Para cada imagen de prueba, nos basamos en el diccionario y usamos el bounding box que ya calculamos.\n",
    "\n",
    "Recortamos la imagen, le calculamos el histograma. Sumamos los histogramas de todas las imágenes y obtenemos la suma total.\n",
    "\n",
    "Luego hacemos lo mismo y al recortar la roi de cada imagen convertimos la roi de rgb a hsv, calculamos el histograma\n",
    "y obtenemos la suma de todos los histogramas. \n",
    "\n",
    "Con estas cosas deberíamos poder obtener los thresholds a aplicar luego.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer gráficos chetos de los histogramas. Ajustar con multiples gaussianas, calcular promedio, mediana, std, etc.\n",
    "Compararlos y elegir el mejor.\n",
    "\n",
    "Luego aplicar las máscaras con los thresholds calculados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RGB images tu HUE images\n",
    "\n",
    "# Get stats from HUE images\n",
    "\n",
    "# Plot and compare\n",
    "\n",
    "# Select thresholds (RGB y HUE)\n",
    "\n",
    "# Create masks using previous thresholds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "\n",
    "path_jpg = os.path.join('dataset', 'train', 'jpg')\n",
    "dirs_jpg = os.listdir(path_jpg)\n",
    "\n",
    "def rgb_histogram(gt_dictionary, path_jpg):\n",
    "\n",
    "    r_hist = np.zeros(255)\n",
    "    g_hist = np.zeros(255)\n",
    "    b_hist = np.zeros(255)\n",
    "\n",
    "    for gt, values in list(gt_dictionary.items()):\n",
    "        for v in values:\n",
    "\n",
    "            jpg_name = gt.replace('gt.', '').replace('txt', 'jpg')\n",
    "            jpg_roi = imageio.imread(os.path.join(path_jpg, jpg_name))[v['tly']:v['bry'], v['tlx']:v['brx']]\n",
    "\n",
    "            bins = np.histogram(jpg_roi[:,:,0], bins=255, range=(1,255))[1]\n",
    "            r_hist += np.histogram(jpg_roi[:,:,0], bins=255, range=(1,255))[0]\n",
    "            g_hist += np.histogram(jpg_roi[:,:,1], bins=255, range=(1,255))[0]\n",
    "            b_hist += np.histogram(jpg_roi[:,:,2], bins=255, range=(1,255))[0]\n",
    "    \n",
    "    return bins, r_hist, g_hist, b_hist\n",
    "\n",
    "\n",
    "def hsv_histogram(gt_dictionary, path_jpg):\n",
    "\n",
    "    h_hist = np.zeros(255)\n",
    "    s_hist = np.zeros(255)\n",
    "    v_hist = np.zeros(255)\n",
    "\n",
    "    for gt, values in list(gt_dictionary.items()):\n",
    "        for v in values:\n",
    "\n",
    "            jpg_name = gt.replace('gt.', '').replace('txt', 'jpg')\n",
    "            jpg_roi = imageio.imread(os.path.join(path_jpg, jpg_name))[v['tly']:v['bry'], v['tlx']:v['brx']]\n",
    "            hsv_roi = color.rgb2hsv(jpg_roi)*255\n",
    "            \n",
    "            bins = np.histogram(hsv_roi[:,:,0], bins=255, range=(1,255))[1]\n",
    "            h_hist += np.histogram(hsv_roi[:,:,0], bins=255, range=(1,255))[0]\n",
    "            s_hist += np.histogram(hsv_roi[:,:,1], bins=255, range=(1,255))[0]\n",
    "            v_hist += np.histogram(hsv_roi[:,:,2], bins=255, range=(1,255))[0]\n",
    "    \n",
    "    return bins, h_hist, s_hist, v_hist\n",
    "\n",
    "################################################\n",
    "# Calculate histograms with traffic signal data:\n",
    "################################################\n",
    "\n",
    "# RGB histograms:\n",
    "\n",
    "bins, r_hist, g_hist, b_hist = rgb_histogram(data, path_jpg)\n",
    "\n",
    "# HSV histograms:\n",
    "\n",
    "hbins, h_hist, s_hist, v_hist = hsv_histogram(data, path_jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions: why can't I use the variable 'bins' to plot the histograms?\n",
    "# Why do I get a divergence at 255?\n",
    "# Why am I dividing by zero when converting to HSV?\n",
    "\n",
    "def plot_histogram(hist, color_name, color_plot):\n",
    "\n",
    "    x = np.arange(255)\n",
    "\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.bar(x, hist, color=color_plot)\n",
    "    plt.ylim((0,60000))\n",
    "    plt.title(color_name + ' histogram')\n",
    "    plt.xlabel('8bit quantification')\n",
    "    plt.ylabel('Total number of px')\n",
    "    plt.show()\n",
    "    \n",
    "# Plot RGB histograms:\n",
    "\n",
    "plot_histogram(r_hist, 'Red', 'r')\n",
    "plot_histogram(g_hist, 'Green', 'g')\n",
    "plot_histogram(b_hist, 'Blue', 'b')\n",
    "\n",
    "# Plot HSV histograms:\n",
    "\n",
    "plot_histogram(h_hist, 'H', 'r')\n",
    "plot_histogram(s_hist, 'S', 'g')\n",
    "plot_histogram(v_hist, 'V', 'b')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item 4 - Evaluate colour masks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparar las máscaras obtenidas con el ground truth.\n",
    "\n",
    "Podemos ver si sirven las funciones que ya nos dieron hechas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lo que sigue a partir de aqui fueron pruebas hechas el martes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['gt.00.005025.txt'][0])\n",
    "print(data['gt.00.005025.txt'][1])\n",
    "\n",
    "for gt in dirs_txt:\n",
    "    print(data[gt][0]['filling_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask in dirs_mask:\n",
    "    gt = mask.replace('mask', 'gt').replace('png', 'txt')\n",
    "    m = (imageio.imread(os.path.join(path_mask, mask)))\n",
    "    mask_area = m.sum()\n",
    "    d = data[gt]\n",
    "    d['mask_area'] = mask_area\n",
    "    d['filling_ratio'] = mask_area / d['bbox_area']\n",
    "    \n",
    "    print(d['mask_area'], d['filling_ratio'], mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dirs_mask[0].replace('mask', 'gt').replace('png', 'txt'))\n",
    "print(dirs_txt[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "m = imageio.imread(os.path.join(path_mask,'mask.00.005025.png')).astype(np.int8)\n",
    "\n",
    "plt.imshow(m[146:201, 1324:1375])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
