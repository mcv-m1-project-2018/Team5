{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# item 1 - Analyze the dataset\n",
    "Parse the groundtruth information into a dictionary and a pandas table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path_txt = os.path.join('dataset', 'train', 'gt')\n",
    "path_mask = os.path.join('dataset', 'train', 'mask')\n",
    "\n",
    "dirs_txt = os.listdir(path_txt)\n",
    "dirs_mask = os.listdir(path_mask)\n",
    "\n",
    "data = dict()\n",
    "\n",
    "for gt in dirs_txt:\n",
    "    with open(os.path.join(path_txt, gt)) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        im_name = gt.replace('gt', 'mask').replace('txt', 'png')\n",
    "        im_open = (imageio.imread(os.path.join(path_mask, im_name)))\n",
    "\n",
    "        lista = list()\n",
    "        \n",
    "        # Extract grountruth information\n",
    "        for l in lines:\n",
    "            tly, tlx, bry, brx, tipo = l.split(' ')  \n",
    "            tly, tlx, bry, brx = map(float, [tly, tlx, bry, brx])\n",
    "            d = dict()\n",
    "            d['type'] = tipo.strip()\n",
    "            \n",
    "            w = brx - tlx\n",
    "            h = bry - tly\n",
    "            \n",
    "            d['width'] = w\n",
    "            d['height'] = h\n",
    "            d['bbox_area'] = w*h\n",
    "            d['form_factor'] = w/h\n",
    "            \n",
    "            d['tly'] = round(tly)\n",
    "            d['tlx'] = round(tlx)\n",
    "            d['bry'] = round(bry)\n",
    "            d['brx'] = round(brx)\n",
    "            \n",
    "            sub_mask = im_open[d['tly']:d['bry'], d['tlx']:d['brx']]\n",
    "            mask_area = np.count_nonzero(sub_mask)\n",
    "            d['mask_area'] = mask_area\n",
    "            d['filling_ratio'] = mask_area / d['bbox_area']\n",
    "            \n",
    "            lista.append(d)\n",
    "            \n",
    "        data[gt] = lista\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show information in pandas format\n",
    "columns = ['type','width','height','form_factor','bbox_area','mask_area','filling_ratio']\n",
    "df = pd.DataFrame.from_dict({(i,n): data[i][n]\n",
    "                        for i in data.keys()\n",
    "                        for n,v in enumerate(data[i])}, columns=columns, orient='index').sort_values(['type'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Maximum values\")\n",
    "type_counts = df.groupby('type').aggregate(max)\n",
    "print(type_counts)\n",
    "\n",
    "type_counts = df.groupby('type').aggregate(min)\n",
    "print(\"\\n\\nMinimum values\")\n",
    "print(type_counts)\n",
    "\n",
    "print(\"\\n\\nSummatory\")\n",
    "type_counts = df.drop(columns=['form_factor','filling_ratio']).groupby('type').aggregate(sum)\n",
    "print(type_counts)\n",
    "\n",
    "type_counts['mask_area'].plot(figsize=(12, 8),kind='pie',sort_columns=True, title=\"Number of pixels per class\")\n",
    "normalized_df=type_counts['mask_area']/type_counts['mask_area'].sum()\n",
    "print(\"\\n\\nPercentage of pixels per class\")\n",
    "print(normalized_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSIONS: \n",
    "Large range of sizes: \n",
    "- From 90 pixels (about 30x30) to 55919 of area\n",
    "\n",
    "\n",
    "Total number of pixels of each class is very different:\n",
    "- class F: 42%\n",
    "- class B: 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type_counts = df.groupby('type').aggregate(np.average).round(2)\n",
    "print(type_counts)\n",
    "type_counts.drop(columns=['width','height','form_factor']).plot(figsize=(5, 8),kind='bar',sort_columns=True,subplots=True)\n",
    "\n",
    "type_counts = df.groupby('type').aggregate(np.std).round(3)\n",
    "print(type_counts)\n",
    "\n",
    "type_counts = df.groupby('type').aggregate(np.median).round(2)\n",
    "print(type_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "Average and median sizes around 90 pixels\n",
    "\n",
    "Filling_ratio pretty consistent through classes\n",
    "- Triangles: 0.5\n",
    "- Circles: 0.77\n",
    "- Rectangles: 0.99"
   ]
  },
  {

   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item 2 - Split training dataset\n",
    "\n",
    "Extract the 30% of the training images of each class to set up a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of signals per class\n",
    "n_signals = df['type'].value_counts(sort=False).reindex(['A','B','C','D','E','F'])\n",
    "print(n_signals)\n",
    "\n",
    "# Plot\n",
    "df['type'].value_counts(sort=False).reindex(['A','B','C','D','E','F']).plot(figsize=(10, 7),kind='bar',sort_columns=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only one class\n",
    "df_filtered = df[df['type'] == \"B\"]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_train = df_filtered.sample(frac=0.7)\n",
    "df_sorted_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train selection\n",
    "tuple(zip(df_sorted_train.index.get_level_values(0).tolist(),df_sorted_train.index.get_level_values(1).tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete train selection to get validation selection\n",
    "df_sorted_test = pd.concat([df_filtered,df_sorted_train]).drop_duplicates(keep=False)\n",
    "tuple(zip(df_sorted_test.index.get_level_values(0).tolist(),df_sorted_test.index.get_level_values(1).tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to do all the process in one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_class(signal_class, train_percentage):\n",
    "    \n",
    "    # Choose one signal class\n",
    "    df_filtered = df[df['type'] == signal_class]\n",
    "    \n",
    "    # Sample randomly the percentage choosen\n",
    "    df_sorted_train = df_filtered.sample(frac=train_percentage)\n",
    "    \n",
    "    # Save train selection\n",
    "    train_images = tuple(zip(df_sorted_train.index.get_level_values(0).tolist(),df_sorted_train.index.get_level_values(1).tolist()))\n",
    "    \n",
    "    # Delete train selection to get validation selection\n",
    "    df_sorted_test = pd.concat([df_filtered,df_sorted_train]).drop_duplicates(keep=False)\n",
    "    val_images = tuple(zip(df_sorted_test.index.get_level_values(0).tolist(),df_sorted_test.index.get_level_values(1).tolist()))\n",
    "    \n",
    "    return train_images, val_images\n",
    "\n",
    "def split_dataset(data,percentage, classes):\n",
    "    \n",
    "    train_images = []\n",
    "    val_images = []\n",
    "    \n",
    "    for signal_class in classes:\n",
    "        temp_train_images, temp_val_images = split_class(signal_class, percentage)\n",
    "        train_images += temp_train_images\n",
    "        val_images += temp_val_images\n",
    "    return train_images, val_images\n",
    "\n",
    "\n",
    "classes_red = ['A','B','C']\n",
    "classes_blue = ['D','F']\n",
    "classes_mix = ['E']\n",
    "\n",
    "train_images_red, val_images_red = split_dataset(data, 0.7, classes_red)\n",
    "train_images_blue, val_images_blue = split_dataset(data, 0.7, classes_blue)\n",
    "train_images_mix, val_images_mix = split_dataset(data, 0.7, classes_mix)\n",
    "\n",
    "train_images = train_images_red + train_images_blue + train_images_mix\n",
    "val_images = val_images_red + val_images_blue + val_images_mix\n",
    "\n",
    "#print(train_images)\n",
    "#print(val_images)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item 3 - Separation by colour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Para cada imagen de prueba, nos basamos en el diccionario y usamos el bounding box que ya calculamos.\n",
    "\n",
    "Recortamos la imagen, le calculamos el histograma. Sumamos los histogramas de todas las imágenes y obtenemos la suma total.\n",
    "\n",
    "Luego hacemos lo mismo y al recortar la roi de cada imagen convertimos la roi de rgb a hsv, calculamos el histograma\n",
    "y obtenemos la suma de todos los histogramas. \n",
    "\n",
    "Con estas cosas deberíamos poder obtener los thresholds a aplicar luego.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer gráficos chetos de los histogramas. Ajustar con multiples gaussianas, calcular promedio, mediana, std, etc.\n",
    "Compararlos y elegir el mejor.\n",
    "\n",
    "Luego aplicar las máscaras con los thresholds calculados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RGB images tu HUE images\n",
    "\n",
    "# Get stats from HUE images\n",
    "\n",
    "# Plot and compare\n",
    "\n",
    "# Select thresholds (RGB y HUE)\n",
    "\n",
    "# Create masks using previous thresholds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "path_jpg = os.path.join('dataset', 'train')    \n",
    "dirs_jpg = os.listdir(path_jpg)\n",
    "\n",
    "##############################\n",
    "# Calculate color histograms:\n",
    "##############################\n",
    "\n",
    "def color_histogram(gt_dictionary, train_selec, path_jpg, color_space):\n",
    "\n",
    "    c0_hist = np.zeros(255)\n",
    "    c1_hist = np.zeros(255)\n",
    "    c2_hist = np.zeros(255)\n",
    "\n",
    "    for gt, position in train_selec:\n",
    "        v = gt_dictionary[gt][position]\n",
    "\n",
    "        jpg_name = gt.replace('gt.', '').replace('txt', 'jpg')\n",
    "        mask_name = gt.replace('gt', 'mask').replace('txt', 'png')\n",
    "\n",
    "        jpg_roi = imageio.imread(os.path.join(path_jpg, jpg_name))[v['tly']:v['bry'], v['tlx']:v['brx']]\n",
    "        mask_roi = imageio.imread(os.path.join(path_mask, mask_name))[v['tly']:v['bry'], v['tlx']:v['brx']]\n",
    "\n",
    "        if color_space=='rgb':\n",
    "            final_roi = jpg_roi\n",
    "            r0 = 0\n",
    "            rf = 255\n",
    "\n",
    "        elif color_space=='hsv':\n",
    "            final_roi = color.rgb2hsv(jpg_roi) \n",
    "            r0 = 0\n",
    "            rf = 1\n",
    "\n",
    "        elif color_space=='ycbcr':\n",
    "            final_roi = color.rgb2ycbcr(jpg_roi)\n",
    "            r0 = 0\n",
    "            rf = 255\n",
    "\n",
    "        elif color_space=='xyz':\n",
    "            final_roi = color.rgb2xyz(jpg_roi)\n",
    "            r0 = 0\n",
    "            rf = 1\n",
    "\n",
    "        mask_roi[mask_roi==0] = 0\n",
    "        mask_roi[mask_roi!=0] = 1\n",
    "\n",
    "        bins = np.histogram(final_roi[:,:,0] * mask_roi, bins=255, range=(r0,rf))[1]\n",
    "        c0_hist += np.histogram(final_roi[:,:,0] * mask_roi, bins=255, range=(r0,rf))[0]\n",
    "        c1_hist += np.histogram(final_roi[:,:,1] * mask_roi, bins=255, range=(r0,rf))[0]\n",
    "        c2_hist += np.histogram(final_roi[:,:,2] * mask_roi, bins=255, range=(r0,rf))[0]\n",
    "\n",
    "    return bins, c0_hist, c1_hist, c2_hist, r0, rf\n",
    "\n",
    "\n",
    "######################################\n",
    "# Calculate RGB normalized histogram:\n",
    "######################################\n",
    "\n",
    "def norm_histogram(gt_dictionary, train_selec, path_jpg, color_space):\n",
    "\n",
    "    c0_hist = np.zeros(255)\n",
    "    c1_hist = np.zeros(255)\n",
    "    c2_hist = np.zeros(255)\n",
    "    \n",
    "    for gt, position in train_selec:\n",
    "        v = gt_dictionary[gt][position]\n",
    "\n",
    "        jpg_name = gt.replace('gt.', '').replace('txt', 'jpg')\n",
    "        mask_name = gt.replace('gt', 'mask').replace('txt', 'png')\n",
    "\n",
    "        # Important: in order to normalize we need to read THE FULL IMAGE. If we normalize the rois, \n",
    "        # we will be training our algorithm poorly.After trying this, we saw all images have saturated\n",
    "        # pixels (aka normalized image = original image). \n",
    "\n",
    "        # We will normalize the ROIs, knowing this is poorly training the algorithm.\n",
    "\n",
    "        jpg_roi = imageio.imread(os.path.join(path_jpg, jpg_name))[v['tly']:v['bry'], v['tlx']:v['brx']]\n",
    "        mask_roi = imageio.imread(os.path.join(path_mask, mask_name))[v['tly']:v['bry'], v['tlx']:v['brx']]\n",
    "\n",
    "        jpg_max_0 = np.max(jpg_roi[:,:,0])\n",
    "        jpg_max_1 = np.max(jpg_roi[:,:,1])\n",
    "        jpg_max_2 = np.max(jpg_roi[:,:,2])\n",
    "\n",
    "        if color_space=='rgb':\n",
    "            final_roi = jpg_roi\n",
    "            jpg_max_0, jpg_max_1, jpg_max_2 = jpg_max_0, jpg_max_1, jpg_max_2 \n",
    "\n",
    "        mask_roi[mask_roi==0] = 0\n",
    "        mask_roi[mask_roi!=0] = 1\n",
    "\n",
    "        bins = np.histogram(final_roi[:,:,0] * mask_roi, bins=255, range=(0,1))[1]\n",
    "        c0_hist += np.histogram(final_roi[:,:,0] / jpg_max_0 * mask_roi, bins=255, range=(0,1))[0]\n",
    "        c1_hist += np.histogram(final_roi[:,:,1] / jpg_max_1 * mask_roi, bins=255, range=(0,1))[0]\n",
    "        c2_hist += np.histogram(final_roi[:,:,2] / jpg_max_2 * mask_roi, bins=255, range=(0,1))[0]\n",
    "\n",
    "    return bins, c0_hist, c1_hist, c2_hist\n",
    "\n",
    "\n",
    "###################\n",
    "# Plot histograms:\n",
    "###################\n",
    "\n",
    "def plot_histogram(hist0, hist1, hist2, r0, rf, color_name):\n",
    "    \n",
    "    path_figures = os.path.join('figures')\n",
    "    try:\n",
    "        os.stat(path_figures)\n",
    "    except:\n",
    "        os.mkdir(path_figures)\n",
    "\n",
    "    x = np.linspace(r0, rf, 255)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    \n",
    "    axs[0].bar(x[:-2], hist0[1:-1], color='r', width=0.8*(rf-r0)/255, label='Ch1')\n",
    "    axs[1].bar(x[:-2], hist1[1:-1], color='g', width=0.8*(rf-r0)/255, label='Ch2')\n",
    "    axs[2].bar(x[:-2], hist2[1:-1], color='b', width=0.8*(rf-r0)/255, label='Ch3')\n",
    "\n",
    "    axs[0].legend()\n",
    "    axs[1].legend()\n",
    "    axs[2].legend()\n",
    "\n",
    "    axs[0].set_xlabel('8bit quantification')\n",
    "    axs[1].set_xlabel('8bit quantification')\n",
    "    axs[2].set_xlabel('8bit quantification')\n",
    "    axs[0].set_ylabel('Total number of px')\n",
    "    \n",
    "    fig.suptitle(color_name + ' histogram')\n",
    "    plt.savefig('figures/' + str(color_name) + '_hist.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate histograms in different color spaces:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to decide the color thresholds, we perform a histogram over the signals of interest.\n",
    "For this purpose, we split the signals by color and calculate the histogram of each group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RGB histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, r_hist_red, g_hist_red, b_hist_red, rgb0, rgbf = color_histogram(data, train_images_red, path_jpg, 'rgb')\n",
    "bins, r_hist_blue, g_hist_blue, b_hist_blue, rgb0_blue, rgbf = color_histogram(data, train_images_blue, path_jpg, 'rgb')\n",
    "bins, r_hist_mix, g_hist_mix, b_hist_mix, rgb0, rgbf = color_histogram(data, train_images_mix, path_jpg, 'rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized RGB histograms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** in order to normalize we need to read THE FULL IMAGE. If we normalize the rois, \n",
    "we will be training our algorithm poorly.After trying this, we saw all images have saturated\n",
    "pixels (aka normalized image = original image). \n",
    "\n",
    "We will normalize the ROIs, knowing this is poorly training the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_norm, r_hist_norm_red, g_hist_norm_red, b_hist_norm_red = norm_histogram(data, train_images_red, path_jpg, 'rgb')\n",
    "bins_norm, r_hist_norm_blue, g_hist_norm_blue, b_hist_norm_blue = norm_histogram(data, train_images_blue, path_jpg, 'rgb')\n",
    "bins_norm, r_hist_norm_mix, g_hist_norm_mix, b_hist_norm_mix = norm_histogram(data, train_images_mix, path_jpg, 'rgb')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HSV histograms:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbins, h_hist_red, s_hist_red, v_hist_red, hsv0, hsvf = color_histogram(data, train_images_red, path_jpg, 'hsv')\n",
    "hbins, h_hist_blue, s_hist_blue, v_hist_blue, hsv0, hsvf = color_histogram(data, train_images_blue, path_jpg, 'hsv')\n",
    "hbins, h_hist_mix, s_hist_mix, v_hist_mix, hsv0, hsvf = color_histogram(data, train_images_mix, path_jpg, 'hsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yCbCr histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ybins, y_hist_red, cb_hist_red, cr_hist_red, ycbcr0, ycbcrf = color_histogram(data, train_images_red, path_jpg, 'ycbcr')\n",
    "ybins, y_hist_blue, cb_hist_blue, cr_hist_blue, ycbcr0, ycbcrf = color_histogram(data, train_images_blue, path_jpg, 'ycbcr')\n",
    "ybins, y_hist_mix, cb_hist_mix, cr_hist_mix, ycbcr0, ycbcrf = color_histogram(data, train_images_mix, path_jpg, 'ycbcr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X,Y,Z histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbins, xx_hist_red, yy_hist_red, zz_hist_red, xyz0, xyzf = color_histogram(data, train_images_red, path_jpg, 'xyz')\n",
    "xbins, xx_hist_blue, yy_hist_blue, zz_hist_blue, xyz0, xyzf = color_histogram(data, train_images_blue, path_jpg, 'xyz')\n",
    "xbins, xx_hist_mix, yy_hist_mix, zz_hist_mix, xyz0, xyzf = color_histogram(data, train_images_mix, path_jpg, 'xyz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot histograms in different color spaces:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot RGB histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(r_hist_red, g_hist_red, b_hist_red, rgb0, rgbf, 'RGB - Red Signals')\n",
    "plot_histogram(r_hist_blue, g_hist_blue, b_hist_blue, rgb0, rgbf, 'RGB - Blue Signals')\n",
    "plot_histogram(r_hist_mix, g_hist_mix, b_hist_mix, rgb0, rgbf, 'RGB - Mixed Signals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot normalized RGB histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(r_hist_norm_red, g_hist_norm_red, b_hist_norm_red, rgb0, rgbf, 'RGB Norm - Red Signals')\n",
    "plot_histogram(r_hist_norm_blue, g_hist_norm_blue, b_hist_norm_blue, rgb0, rgbf, 'RGB Norm - Blue Signals')\n",
    "plot_histogram(r_hist_norm_mix, g_hist_norm_mix, b_hist_norm_mix, rgb0, rgbf, 'RGB Norm - Mixed Signals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot HSV histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(h_hist_red, s_hist_red, v_hist_red, hsv0, hsvf, 'HSV - Red signals')\n",
    "plot_histogram(h_hist_blue, s_hist_blue, v_hist_blue, hsv0, hsvf, 'HSV - Blue signals')\n",
    "plot_histogram(h_hist_mix, s_hist_mix, v_hist_mix, hsv0, hsvf, 'HSV - Mixed signals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot yCbCr histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(y_hist_red, cb_hist_red, cr_hist_red, ycbcr0, ycbcrf, 'yCbCr - Red signals')\n",
    "plot_histogram(y_hist_blue, cb_hist_blue, cr_hist_blue, ycbcr0, ycbcrf, 'yCbCr - Blue signals')\n",
    "plot_histogram(y_hist_mix, cb_hist_mix, cr_hist_mix, ycbcr0, ycbcrf, 'yCbCr - Mixed signals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot xyz histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [

    "plot_histogram(xx_hist_red, yy_hist_red, zz_hist_red, xyz0, xyzf, 'XYZ - Red signals')\n",
    "plot_histogram(xx_hist_blue, yy_hist_blue, zz_hist_blue, xyz0, xyzf, 'XYZ - Blue signals')\n",
    "plot_histogram(xx_hist_mix, yy_hist_mix, zz_hist_mix, xyz0, xyzf, 'XYZ - Mixed signals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [

    "# Normalized RGB histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "\n",
    "path_jpg = os.path.join('dataset', 'train')\n",
    "dirs_jpg = os.listdir(path_jpg)\n",
    "\n",
    "def norm_histogram(gt_dictionary, train_selec, path_jpg, color_space):\n",
    "\n",
    "    c0_hist = np.zeros(255)\n",
    "    c1_hist = np.zeros(255)\n",
    "    c2_hist = np.zeros(255)\n",
    "    \n",
    "    for gt, position in train_selec:\n",
    "        v = gt_dictionary[gt][position]\n",
    "\n",
    "        jpg_name = gt.replace('gt.', '').replace('txt', 'jpg')\n",
    "        mask_name = gt.replace('gt', 'mask').replace('txt', 'png')\n",
    "\n",
    "        # Important: in order to normalize we need to read THE FULL IMAGE. If we normalize the rois, \n",
    "        # we will be training our algorithm poorly.After trying this, we saw all images have saturated\n",
    "        # pixels (aka normalized image = original image). \n",
    "\n",
    "        # We will normalize the ROIs, knowing this is poorly training the algorithm.\n",
    "\n",
    "        jpg_roi = imageio.imread(os.path.join(path_jpg, jpg_name))[v['tly']:v['bry'], v['tlx']:v['brx']]\n",
    "        mask_roi = imageio.imread(os.path.join(path_mask, mask_name))[v['tly']:v['bry'], v['tlx']:v['brx']]\n",
    "\n",
    "        jpg_max_0 = np.max(jpg_roi[:,:,0])\n",
    "        jpg_max_1 = np.max(jpg_roi[:,:,1])\n",
    "        jpg_max_2 = np.max(jpg_roi[:,:,2])\n",
    "\n",
    "        if color_space=='rgb':\n",
    "            final_roi = jpg_roi\n",
    "            jpg_max_0, jpg_max_1, jpg_max_2 = jpg_max_0, jpg_max_1, jpg_max_2 \n",
    "\n",
    "        mask_roi[mask_roi==0] = 0\n",
    "        mask_roi[mask_roi!=0] = 1\n",
    "\n",
    "        bins = np.histogram(final_roi[:,:,0] * mask_roi, bins=255, range=(0,1))[1]\n",
    "        c0_hist += np.histogram(final_roi[:,:,0] / jpg_max_0 * mask_roi, bins=255, range=(0,1))[0]\n",
    "        c1_hist += np.histogram(final_roi[:,:,1] / jpg_max_1 * mask_roi, bins=255, range=(0,1))[0]\n",
    "        c2_hist += np.histogram(final_roi[:,:,2] / jpg_max_2 * mask_roi, bins=255, range=(0,1))[0]\n",
    "\n",
    "    return bins, c0_hist, c1_hist, c2_hist\n",
    "\n",
    "\n",
    "################################################\n",
    "# Calculate histograms with traffic signal data:\n",
    "################################################\n",
    "\n",
    "# RGB histograms:\n",
    "\n",
    "bins_norm, r_hist_norm, g_hist_norm, b_hist_norm = norm_histogram(data, train_images, path_jpg, 'rgb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot normalized histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(r_hist_norm, 0, 1, 'Red_norm', 'r')\n",
    "plot_histogram(g_hist_norm, 0, 1, 'Green_norm', 'g')\n",
    "plot_histogram(b_hist_norm, 0, 1, 'Blue_norm', 'b')"

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [

    "Comparar las máscaras obtenidas con el ground truth.\n",
    "\n",
    "Podemos ver si sirven las funciones que ya nos dieron hechas.\n",
    "\n",
    "## Conclusions: \n",
    "We only study the colors of the signals, so we expect to have False Positives of the same colors in the background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lo que sigue a partir de aqui fueron pruebas hechas el martes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['gt.00.005025.txt'][0])\n",
    "print(data['gt.00.005025.txt'][1])\n",
    "\n",
    "for gt in dirs_txt:\n",
    "    print(data[gt][0]['filling_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask in dirs_mask:\n",
    "    gt = mask.replace('mask', 'gt').replace('png', 'txt')\n",
    "    m = (imageio.imread(os.path.join(path_mask, mask)))\n",
    "    mask_area = m.sum()\n",
    "    d = data[gt]\n",
    "    d['mask_area'] = mask_area\n",
    "    d['filling_ratio'] = mask_area / d['bbox_area']\n",
    "    \n",
    "    print(d['mask_area'], d['filling_ratio'], mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dirs_mask[0].replace('mask', 'gt').replace('png', 'txt'))\n",
    "print(dirs_txt[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "m = imageio.imread(os.path.join(path_mask,'mask.00.005025.png')).astype(np.int8)\n",
    "\n",
    "plt.imshow(m[146:201, 1324:1375])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
